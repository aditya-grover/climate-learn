dataset: "era5"
data_dir: "/local2/hbansal/era5/5.625deg_npz/"
# data_dir: "/data0/datasets/weatherbench/data/weatherbench/era5/5.625deg_npz/"
in_variables: [
  '2m_temperature',
#   '10m_u_component_of_wind',
#   '10m_v_component_of_wind',
#   'toa_incident_solar_radiation',
  'geopotential_50',
  'geopotential_250',
  'geopotential_500',
  'geopotential_600',
  'geopotential_700',
  'geopotential_850',
  'geopotential_925',
  'specific_humidity_50',
  'specific_humidity_250',
  'specific_humidity_500',
  'specific_humidity_600',
  'specific_humidity_700',
  'specific_humidity_850',
  'specific_humidity_925',
  'temperature_50',
  'temperature_250',
  'temperature_500',
  'temperature_600',
  'temperature_700',
  'temperature_850',
  'temperature_925',
  'u_component_of_wind_50',
  'u_component_of_wind_250',
  'u_component_of_wind_500',
  'u_component_of_wind_600',
  'u_component_of_wind_700',
  'u_component_of_wind_850',
  'u_component_of_wind_925',
  'v_component_of_wind_50',
  'v_component_of_wind_250',
  'v_component_of_wind_500',
  'v_component_of_wind_600',
  'v_component_of_wind_700',
  'v_component_of_wind_850',
  'v_component_of_wind_925',
#   'relative_humidity_50',
#   'relative_humidity_250',
#   'relative_humidity_500',
#   'relative_humidity_600',
#   'relative_humidity_700',
#   'relative_humidity_850',
#   'relative_humidity_925',
  ]
# in_variables: ["geopotential_500"]
# in_variables: ["2m_temperature", "geopotential_500", "temperature_850"]
out_variables: ["2m_temperature", "geopotential_500", "temperature_850"]
# out_variables: ["geopotential_500"]
constants: ["land_sea_mask", "orography", "lattitude"]
# constants: []
pred_range: 72
subsample: 1
history: 1
window: 6
num_workers: 1

model: 'swin_pretrained'

in_img_size: [512, 512]
decoder_depth: 2
#if vit_pretrained, this must be consistent with the pretrained model's embed dim
embed_dim: 192
out_embed_dim: 256
#for pretrained model only if use_pretrained_embeddings is false
patch_size: 4
learn_pos_emb: True
mlp_embed_depth: 1
flatten_patch: False
embed_norm: True
#not for vit_pretrained
num_heads: 8
mlp_ratio: 4
depth: 8
drop_path: 0.1
drop_rate: 0.1

# pretrained_model: "vit_small_patch14_dinov2.lvd142m"
pretrained_model: "mask2former"
use_pretrained_weights: True
use_pretrained_embeddings: False
freeze_backbone: False
freeze_embeddings: False
resize_img: True

batch_size: 16
patience: 5
num_epochs: 50
seed: 42
pretrained_lr: 5.0e-7
new_lr: 5.0e-7
warmup_epochs: 5
warmup_start_lr: 1.0e-8
eta_min: 1.0e-8
weight_decay: 1.0e-5
betas: [0.9, 0.99]
val_every_n_steps: 1000

#GPU!!
gpu: [0,1,2,3]
ckpt: 'ff8rrlfn'
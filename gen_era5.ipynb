{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prakharsharma/miniconda3/envs/cl_exp/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Standard library\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Third party\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import netCDF4 as nc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Local application\n",
    "from src.climate_learn.data.climate_dataset.era5.constants import (\n",
    "    DEFAULT_PRESSURE_LEVELS,\n",
    "    NAME_TO_VAR,\n",
    "    VAR_TO_NAME,\n",
    "    CONSTANTS,\n",
    ")\n",
    "\n",
    "HOURS_PER_YEAR = 8736  # 8760 --> 8736 which is dividable by 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nc2np(path, variables, years, save_dir, partition, num_shards_per_year):\n",
    "    os.makedirs(os.path.join(save_dir, partition), exist_ok=True)\n",
    "\n",
    "    if partition == \"train\":\n",
    "        normalize_mean = {}\n",
    "        normalize_std = {}\n",
    "    climatology = {}\n",
    "\n",
    "    constants_path = os.path.join(path, \"constants.nc\")\n",
    "    constants_are_downloaded = os.path.isfile(constants_path)\n",
    "\n",
    "    if constants_are_downloaded:\n",
    "        constants = xr.open_mfdataset(\n",
    "            constants_path, combine=\"by_coords\", parallel=True\n",
    "        )\n",
    "        constant_fields = [VAR_TO_NAME[v] for v in CONSTANTS if v in VAR_TO_NAME.keys()]\n",
    "        constant_values = {}\n",
    "        for f in constant_fields:\n",
    "            constant_values[f] = np.expand_dims(\n",
    "                constants[NAME_TO_VAR[f]].to_numpy(), axis=(0, 1)\n",
    "            ).repeat(HOURS_PER_YEAR, axis=0)\n",
    "            if partition == \"train\":\n",
    "                normalize_mean[f] = constant_values[f].mean(axis=(0, 2, 3))\n",
    "                normalize_std[f] = constant_values[f].std(axis=(0, 2, 3))\n",
    "\n",
    "    for year in tqdm(years):\n",
    "        np_vars = {}\n",
    "\n",
    "        # constant variables\n",
    "        if constants_are_downloaded:\n",
    "            for f in constant_fields:\n",
    "                np_vars[f] = constant_values[f]\n",
    "\n",
    "        # non-constant fields\n",
    "        for var in variables:\n",
    "            ps = glob.glob(os.path.join(path, var, f\"*{year}*.nc\"))\n",
    "            ds = xr.open_mfdataset(\n",
    "                ps, combine=\"by_coords\", parallel=True\n",
    "            )  # dataset for a single variable\n",
    "            code = NAME_TO_VAR[var]\n",
    "\n",
    "            if len(ds[code].shape) == 3:  # surface level variables\n",
    "                ds[code] = ds[code].expand_dims(\"val\", axis=1)\n",
    "                # remove the last 24 hours if this year has 366 days\n",
    "                if code == 'tp': # accumulate 6 hours and log transform\n",
    "                    tp = ds[code].to_numpy()\n",
    "                    tp_cum_6hrs = np.cumsum(tp, axis=0)\n",
    "                    tp_cum_6hrs[6:] = tp_cum_6hrs[6:] - tp_cum_6hrs[:-6]\n",
    "                    eps = 0.001\n",
    "                    tp_cum_6hrs = np.log(eps + tp_cum_6hrs) - np.log(eps)\n",
    "                    np_vars[var] = tp_cum_6hrs[-HOURS_PER_YEAR:]\n",
    "                else:\n",
    "                    np_vars[var] = ds[code].to_numpy()[-HOURS_PER_YEAR:]\n",
    "\n",
    "                if partition == \"train\":\n",
    "                    # compute mean and std of each var in each year\n",
    "                    var_mean_yearly = np_vars[var].mean(axis=(0, 2, 3))\n",
    "                    var_std_yearly = np_vars[var].std(axis=(0, 2, 3))\n",
    "                    if var not in normalize_mean:\n",
    "                        normalize_mean[var] = [var_mean_yearly]\n",
    "                        normalize_std[var] = [var_std_yearly]\n",
    "                    else:\n",
    "                        normalize_mean[var].append(var_mean_yearly)\n",
    "                        normalize_std[var].append(var_std_yearly)\n",
    "\n",
    "                clim_yearly = np_vars[var].mean(axis=0)\n",
    "                if var not in climatology:\n",
    "                    climatology[var] = [clim_yearly]\n",
    "                else:\n",
    "                    climatology[var].append(clim_yearly)\n",
    "\n",
    "            else:  # pressure-level variables\n",
    "                assert len(ds[code].shape) == 4\n",
    "                all_levels = ds[\"level\"][:].to_numpy()\n",
    "                all_levels = np.intersect1d(all_levels, DEFAULT_PRESSURE_LEVELS)\n",
    "                for level in all_levels:\n",
    "                    ds_level = ds.sel(level=[level])\n",
    "                    level = int(level)\n",
    "                    # remove the last 24 hours if this year has 366 days\n",
    "                    np_vars[f\"{var}_{level}\"] = ds_level[code].to_numpy()[\n",
    "                        -HOURS_PER_YEAR:\n",
    "                    ]\n",
    "\n",
    "                    if partition == \"train\":\n",
    "                        # compute mean and std of each var in each year\n",
    "                        var_mean_yearly = np_vars[f\"{var}_{level}\"].mean(axis=(0, 2, 3))\n",
    "                        var_std_yearly = np_vars[f\"{var}_{level}\"].std(axis=(0, 2, 3))\n",
    "                        if f\"{var}_{level}\" not in normalize_mean:\n",
    "                            normalize_mean[f\"{var}_{level}\"] = [var_mean_yearly]\n",
    "                            normalize_std[f\"{var}_{level}\"] = [var_std_yearly]\n",
    "                        else:\n",
    "                            normalize_mean[f\"{var}_{level}\"].append(var_mean_yearly)\n",
    "                            normalize_std[f\"{var}_{level}\"].append(var_std_yearly)\n",
    "\n",
    "                    clim_yearly = np_vars[f\"{var}_{level}\"].mean(axis=0)\n",
    "                    if f\"{var}_{level}\" not in climatology:\n",
    "                        climatology[f\"{var}_{level}\"] = [clim_yearly]\n",
    "                    else:\n",
    "                        climatology[f\"{var}_{level}\"].append(clim_yearly)\n",
    "\n",
    "        assert HOURS_PER_YEAR % num_shards_per_year == 0\n",
    "        num_hrs_per_shard = HOURS_PER_YEAR // num_shards_per_year\n",
    "        for shard_id in range(num_shards_per_year):\n",
    "            start_id = shard_id * num_hrs_per_shard\n",
    "            end_id = start_id + num_hrs_per_shard\n",
    "            sharded_data = {k: np_vars[k][start_id:end_id] for k in np_vars.keys()}\n",
    "            np.savez(\n",
    "                os.path.join(save_dir, partition, f\"{year}_{shard_id}.npz\"),\n",
    "                **sharded_data,\n",
    "            )\n",
    "\n",
    "    if partition == \"train\":\n",
    "        for var in normalize_mean.keys():\n",
    "            if not constants_are_downloaded or var not in constant_fields:\n",
    "                normalize_mean[var] = np.stack(normalize_mean[var], axis=0)\n",
    "                normalize_std[var] = np.stack(normalize_std[var], axis=0)\n",
    "\n",
    "        for var in normalize_mean.keys():  # aggregate over the years\n",
    "            if not constants_are_downloaded or var not in constant_fields:\n",
    "                mean, std = normalize_mean[var], normalize_std[var]\n",
    "                # var(X) = E[var(X|Y)] + var(E[X|Y])\n",
    "                variance = (\n",
    "                    (std**2).mean(axis=0)\n",
    "                    + (mean**2).mean(axis=0)\n",
    "                    - mean.mean(axis=0) ** 2\n",
    "                )\n",
    "                std = np.sqrt(variance)\n",
    "                # E[X] = E[E[X|Y]]\n",
    "                mean = mean.mean(axis=0)\n",
    "                normalize_mean[var] = mean\n",
    "                if var == 'total_precipitation':\n",
    "                    normalize_mean[var] = np.zeros_like(normalize_mean[var])\n",
    "                normalize_std[var] = std\n",
    "\n",
    "        np.savez(os.path.join(save_dir, \"normalize_mean.npz\"), **normalize_mean)\n",
    "        np.savez(os.path.join(save_dir, \"normalize_std.npz\"), **normalize_std)\n",
    "\n",
    "    for var in climatology.keys():\n",
    "        climatology[var] = np.stack(climatology[var], axis=0)\n",
    "    climatology = {k: np.mean(v, axis=0) for k, v in climatology.items()}\n",
    "    np.savez(\n",
    "        os.path.join(save_dir, partition, \"climatology.npz\"),\n",
    "        **climatology,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_nc2npz(\n",
    "    root_dir,\n",
    "    save_dir,\n",
    "    variables,\n",
    "    start_train_year,\n",
    "    start_val_year,\n",
    "    start_test_year,\n",
    "    end_year,\n",
    "    num_shards,\n",
    "):\n",
    "    assert (\n",
    "        start_val_year > start_train_year\n",
    "        and start_test_year > start_val_year\n",
    "        and end_year > start_test_year\n",
    "    )\n",
    "    train_years = range(start_train_year, start_val_year)\n",
    "    val_years = range(start_val_year, start_test_year)\n",
    "    test_years = range(start_test_year, end_year)\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    nc2np(root_dir, variables, train_years, save_dir, \"train\", num_shards)\n",
    "    nc2np(root_dir, variables, val_years, save_dir, \"val\", num_shards)\n",
    "    nc2np(root_dir, variables, test_years, save_dir, \"test\", num_shards)\n",
    "\n",
    "    # save lat and lon data\n",
    "    ps = glob.glob(os.path.join(root_dir, variables[0], f\"*{train_years[0]}*.nc\"))\n",
    "    x = xr.open_mfdataset(ps[0], parallel=True)\n",
    "    lat = np.array(x[\"lat\"])\n",
    "    lon = np.array(x[\"lon\"])\n",
    "    np.save(os.path.join(save_dir, \"lat.npy\"), lat)\n",
    "    np.save(os.path.join(save_dir, \"lon.npy\"), lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [28:18<00:00, 53.09s/it]\n",
      "100%|██████████| 2/2 [01:25<00:00, 42.97s/it]\n",
      "100%|██████████| 2/2 [01:48<00:00, 54.32s/it]\n"
     ]
    }
   ],
   "source": [
    "variables = [\n",
    "    \"2m_temperature\",\n",
    "    \"geopotential\",\n",
    "    \"temperature\",\n",
    "    \"specific_humidity\",\n",
    "    \"u_component_of_wind\",\n",
    "    \"v_component_of_wind\"\n",
    "]\n",
    "\n",
    "convert_nc2npz(\n",
    "    \"/data0/datasets/weatherbench/data/weatherbench/era5/2.8125deg/\",\n",
    "    \"/data0/datasets/weatherbench/data/esgf/era5/2.8125deg_npz/\",\n",
    "    variables,\n",
    "    1979,\n",
    "    2011,\n",
    "    2013,\n",
    "    2015,\n",
    "    8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:22<00:00, 11.32s/it]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cl_exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

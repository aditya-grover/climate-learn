{"cells":[{"cell_type":"markdown","metadata":{"id":"99jkSa_KmrDH"},"source":["# Data Processing for Weather Forcasting\n","\n","ClimateLearn makes it super easy to prepare data for your machine learning pipelines. In this tutorial, we'll see how to download [ERA5](https://www.ecmwf.int/en/forecasts/datasets/reanalysis-datasets/era5) data from [WeatherBench](https://github.com/pangeo-data/WeatherBench) and prepare it for both the forecasting and [downscaling](https://uaf-snap.org/how-do-we-do-it/downscaling) tasks. This tutorial is intended for use in Google Colab."]},{"cell_type":"markdown","metadata":{"id":"4keIJ_E33TbD"},"source":["## Google Colab setup\n","You might need to restart the kernel after installing ClimateLearn so that your Colab environment knows to use the correct package versions."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mL-o36tk3TbE"},"outputs":[],"source":["!pip install climate-learn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XQ6YoJGW3TbF"},"outputs":[],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"markdown","metadata":{"id":"e8YzAFjP3TbF"},"source":["## Download\n","\n","The following cell will take several minutes to run - the scale of climate data is huge!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QmQG73ZpQNHP"},"outputs":[],"source":["from climate_learn.data import download\n","\n","root = \"/content/drive/MyDrive/ClimateLearn\"\n","source = \"weatherbench\"\n","dataset = \"era5\"\n","resolution = \"5.625\"\n","variable = \"2m_temperature\"\n","years = range(1979, 2018)\n","\n","download(root=root, source=source, dataset=dataset, resolution=resolution, variable=variable)"]},{"cell_type":"markdown","metadata":{"id":"bSt6h_Q-oqjK"},"source":["ClimateLearn comes with some utilities to view the downloaded data in its raw format. This can be useful as a quick sanity check that you have the data you expect. Climate data is natively stored in the [NetCDF format](https://www.unidata.ucar.edu/software/netcdf/), which means it comes bundled with lots of helpful named metadata such as latitude, longitude, and time. However, we want the data in a form that can be easily ingested by PyTorch machine learning models."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"97hHL2Z7-Z86"},"outputs":[],"source":["from climate_learn.utils.data import load_dataset, view\n","\n","my_dataset = load_dataset(f\"{root}/data/{source}/{dataset}/{resolution}/{variable}\")\n","view(my_dataset)"]},{"cell_type":"markdown","metadata":{"id":"3XM3rITW9Y3-"},"source":["## Preparing data for forecasting"]},{"cell_type":"markdown","metadata":{"id":"fD7fIQ0o3TbH"},"source":["In this cell, we specify the dataset arguments. The temporal range of ERA5 data on WeatherBench is 1979 to 2018."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EK2UD49hQ3om"},"outputs":[],"source":["from climate_learn.data.climate_dataset.args import ERA5Args\n","\n","data_args = ERA5Args(\n","    root_dir=f\"{root}/data/{source}/{dataset}/{resolution}/\",\n","    variables=[variable],\n","    years=years\n",")"]},{"cell_type":"markdown","metadata":{"id":"lI9wgbTL3TbH"},"source":["Now we specify the task arguments. In this case we are interested in forecasting only `2m_temperature` using only `2m_temperature`, but one could specify additional variables, provided that the data for those variables is downloaded. The prediction range is in hours, so if we want to predict 3 days ahead, we provide `3*24`. Further, we subsample every 6 hours of the day since weather conditions do not change significantly on hourly intervals."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2q0u3-sF3TbI"},"outputs":[],"source":["from climate_learn.data.tasks.args import ForecastingArgs\n","\n","forecasting_args = ForecastingArgs(\n","    dataset_args=data_args,\n","    in_vars=[variable],\n","    out_vars=[variable],\n","    pred_range=3*24,\n","    subsample=6\n",")"]},{"cell_type":"markdown","metadata":{"id":"Q3NMda053TbI"},"source":["Finally, we specify the data module, where we define our train-validation-testing split and the batch size."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vKgQAbo23TbI"},"outputs":[],"source":["from climate_learn.data import DataModuleArgs, DataModule\n","\n","data_module_args = DataModuleArgs(\n","    task_args=forecasting_args,\n","    train_start_year=1979,\n","    val_start_year=2015,\n","    test_start_year=2017,\n","    end_year=2018\n",")\n","\n","data_module = DataModule(\n","    data_module_args=data_module_args,\n","    batch_size=128,\n","    num_workers=1\n",")"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":["4keIJ_E33TbD"]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"},"vscode":{"interpreter":{"hash":"5b35d5811d64db97cad819926e9e0ba09b354a75e2ee95b259c11201fc783944"}}},"nbformat":4,"nbformat_minor":0}